{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0e1659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import threading\n",
    "\n",
    "# Load pre-trained cascade classifiers for each type of vehicle\n",
    "car_cascade = cv2.CascadeClassifier(r\"C:\\Users\\91957\\Downloads\\cars.xml\")\n",
    "two_wheeler_cascade = cv2.CascadeClassifier(r\"C:\\Users\\91957\\Downloads\\two_wheeler.xml\")\n",
    "bus_cascade = cv2.CascadeClassifier(r\"C:\\Users\\91957\\Downloads\\Bus_front.xml\")\n",
    "\n",
    "# Define the delay between consecutive vehicle detections (in seconds)\n",
    "detection_delay = 3\n",
    "\n",
    "# Function to detect vehicles in an image\n",
    "def detect_vehicles(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect cars\n",
    "    cars = car_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    # Detect two-wheelers\n",
    "    two_wheelers = two_wheeler_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    # Detect buses\n",
    "    buses = bus_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    \n",
    "    # Combine all detections into a single list\n",
    "    all_vehicles = list(cars) + list(two_wheelers) + list(buses)\n",
    "    \n",
    "    return len(all_vehicles), all_vehicles\n",
    "\n",
    "# Simulate traffic volume data based on the number of detected vehicles\n",
    "def simulate_traffic(total_vehicles):\n",
    "    # Adjust traffic volume based on the total number of detected vehicles\n",
    "    # You can define your logic here to map the number of vehicles to traffic volume\n",
    "    # For simplicity, we'll use a linear mapping\n",
    "    traffic_volume = total_vehicles * 10  # Example: Each vehicle contributes 10 units of traffic volume\n",
    "    return min(100, traffic_volume)  # Ensure traffic volume does not exceed 100\n",
    "\n",
    "# Algorithm to adjust signal duration based on traffic volume\n",
    "def adjust_signal_duration(traffic_volume):\n",
    "    if traffic_volume < 30:\n",
    "        return 3  # Low traffic, short green signal\n",
    "    elif 30 <= traffic_volume < 70:\n",
    "        return 5   # Moderate traffic, medium green signal\n",
    "    else:\n",
    "        return 10   # High traffic, longer green signal\n",
    "\n",
    "# Function to process frames and display traffic information\n",
    "def process_frames():\n",
    "    cap = cv2.VideoCapture(0)  # Use the default camera (change to desired camera index if needed)\n",
    "    \n",
    "    while True:\n",
    "        # Capture frame from camera\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Detect vehicles in the frame\n",
    "        total_vehicles, vehicle_boxes = detect_vehicles(frame)\n",
    "        \n",
    "        # Simulate traffic volume based on the number of detected vehicles\n",
    "        traffic_volume = simulate_traffic(total_vehicles)\n",
    "        \n",
    "        # Adjust signal duration based on traffic volume\n",
    "        signal_duration = adjust_signal_duration(traffic_volume)\n",
    "        \n",
    "        # Draw bounding boxes around detected vehicles\n",
    "        for (x, y, w, h) in vehicle_boxes:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        \n",
    "        # Display the number of vehicles detected\n",
    "        cv2.putText(frame, f\"Total Vehicles: {total_vehicles}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # Display the signal duration\n",
    "        cv2.putText(frame, f\"Signal Duration: {signal_duration} seconds\", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Display the frame with bounding boxes, vehicle count, and signal duration\n",
    "        cv2.imshow('Traffic Monitoring', frame)\n",
    "        \n",
    "        # Introduce a delay between consecutive vehicle detections\n",
    "        time.sleep(detection_delay)\n",
    "        \n",
    "        # Exit loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the camera and close OpenCV windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Run the process_frames function in a separate thread\n",
    "if __name__ == \"__main__\":\n",
    "    thread = threading.Thread(target=process_frames)\n",
    "    thread.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1725a0e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
